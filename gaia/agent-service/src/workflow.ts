import { Agent, AgentInputItem, Runner, withTrace } from "@openai/agents";
import { OpenAI } from "openai";
import { spawn, ChildProcessWithoutNullStreams } from "node:child_process";
import fs from "node:fs";
import os from "node:os";
import path from "node:path";

const openaiClient = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const DEFAULT_REPO_OWNER = process.env.GAIA_REPO_OWNER ?? "capston2025";
const DEFAULT_REPO_NAME = process.env.GAIA_REPO_NAME ?? "capston";
const DEFAULT_MCP_DIR = process.env.GITHUB_MCP_SERVER_DIR ?? path.join(os.homedir(), "á„’á…¡á†¨á„‰á…³á†¸", "github-mcp-server");
const DEFAULT_MCP_BIN = process.env.GITHUB_MCP_SERVER_BIN ?? path.join(DEFAULT_MCP_DIR, "github-mcp-server");

const keywordExtractorSystemPrompt = `Extract up to 8 short feature keywords (2-4 words each) from the specification. \nReturn ONLY a JSON array of strings.\nExamples: ["ë¡œê·¸ì¸", "ì¥ë°”êµ¬ë‹ˆ", "íšŒì›ê°€ì…"]`;

async function extractFeatureKeywords(specText: string): Promise<string[]> {
  try {
    const completion = await openaiClient.chat.completions.create({
      model: "gpt-4o-mini",
      temperature: 0,
      messages: [
        { role: "system", content: keywordExtractorSystemPrompt },
        { role: "user", content: specText.slice(0, 6000) },
      ],
    });
    const raw = completion.choices?.[0]?.message?.content ?? "[]";
    const parsed = JSON.parse(raw);
    if (Array.isArray(parsed)) {
      return [...new Set(parsed.map((item) => String(item).trim()).filter(Boolean))].slice(0, 8);
    }
  } catch (error) {
    console.warn("Keyword extraction failed; falling back to heuristics", error);
  }
  return [...new Set(
    specText
      .split(/\W+/)
      .map((token) => token.trim())
      .filter((token) => token.length > 4)
      .slice(0, 5)
  )];
}

function summarizeSearchResult(keyword: string, payload: string): string | null {
  try {
    const data = JSON.parse(payload);
    const items = data.code_results ?? data.CodeResults ?? data.items ?? [];
    if (!Array.isArray(items) || !items.length) {
      return null;
    }
    const bullets = items.slice(0, 3).map((item: any) => {
      const repo = item.repository?.full_name ?? item.repository?.fullName ?? `${DEFAULT_REPO_OWNER}/${DEFAULT_REPO_NAME}`;
      const filePath = item.path ?? item.Path ?? item.name ?? "unknown";
      const fragment = item.text_matches?.[0]?.fragment ?? item.fragment ?? "";
      const cleaned = fragment ? fragment.replace(/\s+/g, " ").trim().slice(0, 140) : "";
      return `â€¢ ${repo}/${filePath}${cleaned ? ` â†’ ${cleaned}` : ""}`;
    });
    return `Keyword: ${keyword}\n${bullets.join("\n")}`;
  } catch (error) {
    console.warn("Failed to summarize MCP search result", error);
    return null;
  }
}

function buildLocalFallbackContext(): string {
  const files = (process.env.GAIA_REPO_FALLBACK_FILES ?? "README.md,PROJECT.md")
    .split(",")
    .map((token) => token.trim())
    .filter(Boolean);
  const sections: string[] = [];
  for (const relative of files) {
    const abs = path.join(process.cwd(), relative);
    if (!fs.existsSync(abs)) continue;
    try {
      sections.push(`[local] ${relative}\n${fs.readFileSync(abs, "utf8").slice(0, 800).trim()}`);
    } catch (error) {
      console.warn(`Failed to read fallback file ${relative}`, error);
    }
  }
  return sections.join("\n\n");
}

function createResponseWaiter(child: ChildProcessWithoutNullStreams) {
  const pending = new Map<number, (value: any) => void>();
  let buffer = "";

  child.stdout.on("data", (chunk) => {
    buffer += chunk.toString();
    let newlineIndex = buffer.indexOf("\n");
    while (newlineIndex >= 0) {
      const line = buffer.slice(0, newlineIndex).trim();
      buffer = buffer.slice(newlineIndex + 1);
      if (line) {
        try {
          const message = JSON.parse(line);
          const resolver = pending.get(message.id);
          if (resolver) {
            pending.delete(message.id);
            resolver(message);
          }
        } catch (error) {
          console.warn("Invalid MCP line", line, error);
        }
      }
      newlineIndex = buffer.indexOf("\n");
    }
  });

  return (id: number, timeoutMs = 15000) =>
    new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        pending.delete(id);
        reject(new Error(`Timed out waiting for MCP response ${id}`));
      }, timeoutMs);
      pending.set(id, (value) => {
        clearTimeout(timeout);
        resolve(value);
      });
    });
}

async function callGithubMcpTool(toolName: string, args: Record<string, unknown>): Promise<string | null> {
  if (!process.env.GITHUB_PERSONAL_ACCESS_TOKEN) {
    console.warn("GITHUB_PERSONAL_ACCESS_TOKEN not set; skipping MCP call");
    return null;
  }
  if (!fs.existsSync(DEFAULT_MCP_BIN)) {
    console.warn(`github-mcp-server binary missing at ${DEFAULT_MCP_BIN}`);
    return null;
  }

  return await new Promise((resolve) => {
    const child = spawn(DEFAULT_MCP_BIN, ["stdio", "--toolsets=default", "--read-only"], {
      cwd: DEFAULT_MCP_DIR,
      env: { ...process.env },
      stdio: ["pipe", "pipe", "pipe"],
    });

    const waitForResponse = createResponseWaiter(child);

    const cleanup = (value: string | null) => {
      try {
        child.stdin.end();
        child.kill();
      } catch (error) {
        console.warn("Failed to clean MCP process", error);
      }
      resolve(value);
    };

    child.on("error", (error) => {
      console.warn("github-mcp-server failed", error);
      cleanup(null);
    });

    const initPayload = {
      jsonrpc: "2.0",
      id: 1,
      method: "initialize",
      params: {
        protocolVersion: "2024-11-05",
        capabilities: {},
        clientInfo: { name: "gaia-agent-builder", version: "0.2" },
      },
    };
    child.stdin.write(`${JSON.stringify(initPayload)}\n`);

    waitForResponse(1)
      .then(() => {
        const callPayload = {
          jsonrpc: "2.0",
          id: 2,
          method: "tools/call",
          params: { name: toolName, arguments: args },
        };
        child.stdin.write(`${JSON.stringify(callPayload)}\n`);
        return waitForResponse(2);
      })
      .then((message: any) => {
        child.stdin.write(`${JSON.stringify({ jsonrpc: "2.0", id: 3, method: "shutdown" })}\n`);
        const text = message?.result?.content?.find((item: any) => item?.type === "text")?.text ?? null;
        if (text && !text.includes("failed to")) {
          cleanup(text);
        } else {
          cleanup(null);
        }
      })
      .catch((error) => {
        console.warn("MCP request failed", error);
        cleanup(null);
      });
  });
}

async function collectRepoContext(keywords: string[]): Promise<string> {
  const sections: string[] = [];
  for (const keyword of keywords.slice(0, 5)) {
    const query = `repo:${DEFAULT_REPO_OWNER}/${DEFAULT_REPO_NAME} ${keyword}`;
    const raw = await callGithubMcpTool("search_code", { query, perPage: 3 });
    if (raw) {
      const summary = summarizeSearchResult(keyword, raw);
      if (summary) {
        sections.push(summary);
        continue;
      }
    }
    const fallback = buildLocalFallbackContext();
    if (fallback) {
      sections.push(`Keyword: ${keyword}\n${fallback}`);
    }
  }
  return sections.join("\n\n");
}

async function augmentSpecWithRepoContext(specText: string): Promise<string> {
  const keywords = await extractFeatureKeywords(specText);
  if (!keywords.length) {
    return specText;
  }
  const repoContext = await collectRepoContext(keywords);
  if (!repoContext.trim()) {
    return specText;
  }
  return `${specText}\n\n### Repo Context (auto-collected)\n${repoContext}`;
}

const broadFeatureAgent = new Agent({
  name: "Broad Feature Agent",
  instructions: `ğŸ¯ Goal: ì „ ì‚¬ì´íŠ¸/ë¬¸ì„œë¥¼ í›‘ìœ¼ë©° í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ ëª¨ë“  ê¸°ëŠ¥ì„ í•œ ì¤„ ë‹¨ìœ„ë¡œ ì „ìˆ˜ì¡°ì‚¬í•˜ë¼.\n- ì ˆëŒ€ ìš”ì•½ ê¸ˆì§€, ìœ ì‚¬ ê¸°ëŠ¥ë„ ê°ê° ì¶œë ¥\n- ì…ë ¥â†’ê²€ì¦â†’ì €ì¥ ë“± ì—¬ëŸ¬ ë™ì‘ì€ ê°ê° ë¼ì¸ìœ¼ë¡œ ë¶„ë¦¬\n- [ê¸°ëŠ¥ëª…] : category - ì„¤ëª… í˜•ì‹ì„ ìœ ì§€\n- categoryëŠ” form / interaction / navigation / data / ui / feedback / accessibility ì¤‘ í•˜ë‚˜\n- Plain text only (JSON, Markdown ê¸ˆì§€)`,
  model: "gpt-5",
  modelSettings: {
    reasoning: { effort: "low", summary: "auto" },
    store: true,
  },
});

const targetedFeatureAgent = new Agent({
  name: "Filter Summarizer Agent",
  instructions: `user_request í‚¤ì›Œë“œì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ëœ ê¸°ëŠ¥ë§Œ í•„í„°ë§í•˜ì—¬ [ê¸°ëŠ¥ëª…] : category - ì„¤ëª… í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ë¼.\nìš”ì²­ëœ ê¸°ëŠ¥êµ°ì—ì„œëŠ” ì„±ê³µ/ì˜¤ë¥˜/ê²½ê³„/ìë™ë™ì‘ ë“±ì„ ëª¨ë‘ ì„¸ë¶„í™”í•˜ê³ , ê·¸ ì™¸ ì˜ì—­ì€ ë¬´ì‹œí•œë‹¤.`,
  model: "gpt-5",
  modelSettings: {
    reasoning: { effort: "low", summary: "auto" },
    store: true,
  },
});

const testCaseGeneratorAgent = new Agent({
  name: "Test Case Generator",
  instructions: `ì£¼ì–´ì§„ ê¸°ëŠ¥ ë¦¬ìŠ¤íŠ¸(Plain text)ë¥¼ GAIAìš© TC JSONìœ¼ë¡œ ë³€í™˜í•œë‹¤.\n- ìµœì†Œ 2~5ê°œ variant (ì •ìƒ/ì˜¤ë¥˜/ê²½ê³„)ë¥¼ ìƒì„±\n- stepsëŠ” ìì—°ì–´ ì•¡ì…˜, selector ê¸ˆì§€\n- expected_resultëŠ” ìƒíƒœ ê¸°ë°˜, í† ìŠ¤íŠ¸/íŒì—… ëŒ€ì‹  í™”ë©´ ìƒíƒœ í™•ì¸\n- ì¶œë ¥ì€ { "checklist": [...], "summary": {...}, "has_next": bool } JSON í•˜ë‚˜ë§Œ í—ˆìš©`,
  model: "gpt-5",
  modelSettings: {
    reasoning: { effort: "low", summary: "auto" },
    store: true,
  },
});

const scenarioSplitterAgent = new Agent({
  name: "Scenario Splitter",
  instructions: `TC JSONì„ ë°›ì•„ loose-mode RT JSONìœ¼ë¡œ ë³€í™˜í•œë‹¤.\n- TC001-1 â†’ RT001 (ìˆœì°¨ ID)\n- categoryì— ë”°ë¼ goto URL hash ê²°ì • (formâ†’#forms, interactionâ†’#interactions, etc.)\n- "í˜ì´ì§€ì— ì ‘ì†" â†’ goto + wait(800ms)\n- ì…ë ¥/í´ë¦­ step ì•ì— ê¸°ëŠ¥ëª… prefix ë¶™ì´ê¸°\n- ì œì¶œ/ëª¨ë‹¬ ë’¤ì—ëŠ” wait(600ms/500ms) ì¶”ê°€\n- assertion ê°ì²´ í•„ìˆ˜ (expected_result ê¸°ë°˜, expectVisible/expectTrue)\n- selectorëŠ” í•­ìƒ ""`,
  model: "gpt-5",
  modelSettings: {
    reasoning: { effort: "low", summary: "auto" },
    store: true,
  },
});

const jsonMergeAgent = new Agent({
  name: "JSON Merge Agent",
  instructions: `ì—¬ëŸ¬ RT JSONì„ ë‹¨ì¼ ê°ì²´ë¡œ ë³‘í•©í•œë‹¤.\n- profile/urlì€ ì²« ë²ˆì§¸ ì…ë ¥ ì‚¬ìš©, pdf_hash ì—†ìœ¼ë©´ dummy ê°’ ì¶”ê°€\n- test_scenarios ë°°ì—´ì„ ì´ì–´ ë¶™ì´ê³  ID ì¶©ëŒ ì‹œ ë’¤ í•­ëª© ì¬ë²ˆí˜¸ ë¶€ì—¬\n- goto paramsê°€ # ë˜ëŠ” / ë¡œ ì‹œì‘í•˜ë©´ ê¸°ë³¸ URLë¡œ ì ˆëŒ€í™”\n- assertionì´ ë¬¸ìì—´ì´ë©´ { description, selector:"", condition:"expectVisible", params:[] }ë¡œ ë³€í™˜`,
  model: "gpt-5",
  modelSettings: {
    reasoning: { effort: "low", summary: "auto" },
    store: true,
  },
});

function approvalRequest(_message: string) {
  // TODO: hook up to real approval workflow. For now we always request targeted filtering.
  return true;
}

export interface WorkflowInput {
  input_as_text: string;
}

export interface WorkflowOutput {
  output_text: string;
}

export const runWorkflow = async (workflow: WorkflowInput): Promise<WorkflowOutput> => {
  return await withTrace("GAIA Agent Builder", async () => {
    const augmentedInput = await augmentSpecWithRepoContext(workflow.input_as_text);

    const conversationHistory: AgentInputItem[] = [
      {
        role: "user",
        content: [
          {
            type: "input_text",
            text: augmentedInput,
          },
        ],
      },
    ];

    const runner = new Runner({
      traceMetadata: {
        __trace_source__: "agent-builder",
        workflow_id: "wf_github_mcp_augmented_pipeline",
      },
    });

    const approvalMessage = "ì–´ë–¤ ê¸°ëŠ¥ì„ ì§‘ì¤‘í•´ì„œ í…ŒìŠ¤íŠ¸í• ê¹Œìš”? (ì˜ˆ: ë¡œê·¸ì¸, ì¥ë°”êµ¬ë‹ˆ, íšŒì›ê°€ì…)";
    const pipeline = approvalRequest(approvalMessage)
      ? [targetedFeatureAgent, testCaseGeneratorAgent, scenarioSplitterAgent, jsonMergeAgent]
      : [broadFeatureAgent, testCaseGeneratorAgent, scenarioSplitterAgent, jsonMergeAgent];

    let finalOutput = "";
    for (const agent of pipeline) {
      const result = await runner.run(agent, [...conversationHistory]);
      conversationHistory.push(...result.newItems.map((item) => item.rawItem));
      if (!result.finalOutput) {
        throw new Error("Agent result is undefined");
      }
      finalOutput = result.finalOutput;
    }

    return {
      output_text: finalOutput,
    };
  });
};
